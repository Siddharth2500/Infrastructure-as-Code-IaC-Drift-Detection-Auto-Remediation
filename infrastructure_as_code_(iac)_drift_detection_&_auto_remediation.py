# -*- coding: utf-8 -*-
"""Infrastructure as Code (IaC) Drift Detection & Auto-Remediation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

"""
DevOps Project 3: Infrastructure as Code (IaC) Drift Detection & Auto-Remediation
An intelligent system that detects configuration drift in cloud infrastructure, identifies
security vulnerabilities, and automatically generates remediation scripts using ML-based
anomaly detection and policy enforcement.
"""

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import json
import hashlib
import warnings
warnings.filterwarnings('ignore')

class IaCDriftDetector:
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.scaler = StandardScaler()
        self.baseline_config = {}
        self.current_state = None
        self.drift_history = []
        self.remediation_scripts = []
        self.security_violations = []

    def generate_baseline_infrastructure(self):
        """Generate baseline infrastructure configuration (desired state)"""
        baseline = {
            'ec2_instances': [
                {
                    'id': 'i-0abc123',
                    'type': 't3.medium',
                    'ami': 'ami-0c55b159cbfafe1f0',
                    'security_groups': ['sg-production-web'],
                    'iam_role': 'ec2-production-role',
                    'encrypted': True,
                    'public_ip': False,
                    'monitoring': True,
                    'tags': {'Environment': 'production', 'ManagedBy': 'Terraform'},
                    'backup_enabled': True,
                    'last_patched': datetime.now() - timedelta(days=5)
                },
                {
                    'id': 'i-0def456',
                    'type': 't3.large',
                    'ami': 'ami-0c55b159cbfafe1f0',
                    'security_groups': ['sg-production-app'],
                    'iam_role': 'ec2-production-role',
                    'encrypted': True,
                    'public_ip': False,
                    'monitoring': True,
                    'tags': {'Environment': 'production', 'ManagedBy': 'Terraform'},
                    'backup_enabled': True,
                    'last_patched': datetime.now() - timedelta(days=3)
                }
            ],
            's3_buckets': [
                {
                    'name': 'prod-data-bucket',
                    'versioning': True,
                    'encryption': 'AES256',
                    'public_access_blocked': True,
                    'logging_enabled': True,
                    'lifecycle_policy': True,
                    'replication': True,
                    'mfa_delete': True,
                    'tags': {'Environment': 'production', 'DataClass': 'sensitive'}
                },
                {
                    'name': 'prod-backup-bucket',
                    'versioning': True,
                    'encryption': 'aws:kms',
                    'public_access_blocked': True,
                    'logging_enabled': True,
                    'lifecycle_policy': True,
                    'replication': False,
                    'mfa_delete': True,
                    'tags': {'Environment': 'production', 'DataClass': 'backup'}
                }
            ],
            'security_groups': [
                {
                    'id': 'sg-production-web',
                    'ingress_rules': [
                        {'port': 443, 'protocol': 'tcp', 'source': '0.0.0.0/0'},
                        {'port': 80, 'protocol': 'tcp', 'source': '0.0.0.0/0'}
                    ],
                    'egress_rules': [
                        {'port': -1, 'protocol': '-1', 'destination': '0.0.0.0/0'}
                    ],
                    'tags': {'Environment': 'production'}
                },
                {
                    'id': 'sg-production-app',
                    'ingress_rules': [
                        {'port': 8080, 'protocol': 'tcp', 'source': '10.0.0.0/16'}
                    ],
                    'egress_rules': [
                        {'port': -1, 'protocol': '-1', 'destination': '0.0.0.0/0'}
                    ],
                    'tags': {'Environment': 'production'}
                }
            ],
            'rds_instances': [
                {
                    'id': 'prod-database',
                    'engine': 'postgres',
                    'version': '14.7',
                    'instance_class': 'db.r5.large',
                    'multi_az': True,
                    'encrypted': True,
                    'backup_retention': 30,
                    'auto_minor_version_upgrade': True,
                    'publicly_accessible': False,
                    'monitoring_interval': 60,
                    'deletion_protection': True,
                    'tags': {'Environment': 'production', 'ManagedBy': 'Terraform'}
                }
            ],
            'iam_policies': [
                {
                    'name': 'ec2-production-policy',
                    'permissions': ['s3:GetObject', 's3:PutObject', 'cloudwatch:PutMetricData'],
                    'mfa_required': True,
                    'last_modified': datetime.now() - timedelta(days=90)
                }
            ]
        }

        self.baseline_config = baseline
        return baseline

    def simulate_infrastructure_drift(self):
        """Simulate real-world configuration drift scenarios"""
        import copy
        current = copy.deepcopy(self.baseline_config)

        drift_scenarios = []

        # Scenario 1: Manual change - EC2 security group modified
        if np.random.random() < 0.7:
            current['ec2_instances'][0]['security_groups'].append('sg-temporary-ssh')
            drift_scenarios.append({
                'resource': 'ec2_instances[0]',
                'type': 'security_group_change',
                'severity': 'HIGH',
                'description': 'Unauthorized security group attached',
                'field': 'security_groups'
            })

        # Scenario 2: Encryption disabled on S3
        if np.random.random() < 0.5:
            current['s3_buckets'][0]['encryption'] = None
            drift_scenarios.append({
                'resource': 's3_buckets[0]',
                'type': 'encryption_disabled',
                'severity': 'CRITICAL',
                'description': 'S3 bucket encryption disabled',
                'field': 'encryption'
            })

        # Scenario 3: Public access enabled
        if np.random.random() < 0.4:
            current['s3_buckets'][0]['public_access_blocked'] = False
            drift_scenarios.append({
                'resource': 's3_buckets[0]',
                'type': 'public_access_enabled',
                'severity': 'CRITICAL',
                'description': 'S3 bucket made publicly accessible',
                'field': 'public_access_blocked'
            })

        # Scenario 4: SSH port opened to internet
        if np.random.random() < 0.6:
            current['security_groups'][0]['ingress_rules'].append({
                'port': 22, 'protocol': 'tcp', 'source': '0.0.0.0/0'
            })
            drift_scenarios.append({
                'resource': 'security_groups[0]',
                'type': 'insecure_port_opened',
                'severity': 'CRITICAL',
                'description': 'SSH port 22 opened to internet',
                'field': 'ingress_rules'
            })

        # Scenario 5: RDS backup retention reduced
        if np.random.random() < 0.5:
            current['rds_instances'][0]['backup_retention'] = 7
            drift_scenarios.append({
                'resource': 'rds_instances[0]',
                'type': 'backup_policy_weakened',
                'severity': 'MEDIUM',
                'description': 'Backup retention reduced from 30 to 7 days',
                'field': 'backup_retention'
            })

        # Scenario 6: Monitoring disabled
        if np.random.random() < 0.4:
            current['ec2_instances'][1]['monitoring'] = False
            drift_scenarios.append({
                'resource': 'ec2_instances[1]',
                'type': 'monitoring_disabled',
                'severity': 'MEDIUM',
                'description': 'CloudWatch monitoring disabled',
                'field': 'monitoring'
            })

        # Scenario 7: Tags removed
        if np.random.random() < 0.5:
            current['ec2_instances'][0]['tags'].pop('ManagedBy', None)
            drift_scenarios.append({
                'resource': 'ec2_instances[0]',
                'type': 'tag_removal',
                'severity': 'LOW',
                'description': 'ManagedBy tag removed',
                'field': 'tags'
            })

        # Scenario 8: Multi-AZ disabled
        if np.random.random() < 0.3:
            current['rds_instances'][0]['multi_az'] = False
            drift_scenarios.append({
                'resource': 'rds_instances[0]',
                'type': 'high_availability_disabled',
                'severity': 'HIGH',
                'description': 'Multi-AZ deployment disabled',
                'field': 'multi_az'
            })

        # Scenario 9: Versioning disabled
        if np.random.random() < 0.4:
            current['s3_buckets'][1]['versioning'] = False
            drift_scenarios.append({
                'resource': 's3_buckets[1]',
                'type': 'versioning_disabled',
                'severity': 'MEDIUM',
                'description': 'S3 versioning disabled',
                'field': 'versioning'
            })

        # Scenario 10: Deletion protection removed
        if np.random.random() < 0.3:
            current['rds_instances'][0]['deletion_protection'] = False
            drift_scenarios.append({
                'resource': 'rds_instances[0]',
                'type': 'deletion_protection_disabled',
                'severity': 'HIGH',
                'description': 'RDS deletion protection disabled',
                'field': 'deletion_protection'
            })

        self.current_state = current
        return current, drift_scenarios

    def detect_configuration_drift(self):
        """Compare current state with baseline to detect drift"""
        if self.current_state is None:
            print("‚ùå No current state available. Run simulate_infrastructure_drift() first.")
            return None

        drifts = []

        # Check EC2 instances
        for i, baseline_ec2 in enumerate(self.baseline_config['ec2_instances']):
            if i < len(self.current_state['ec2_instances']):
                current_ec2 = self.current_state['ec2_instances'][i]
                drift = self._compare_resources(baseline_ec2, current_ec2, f'ec2_instances[{i}]', 'EC2 Instance')
                if drift:
                    drifts.extend(drift)

        # Check S3 buckets
        for i, baseline_s3 in enumerate(self.baseline_config['s3_buckets']):
            if i < len(self.current_state['s3_buckets']):
                current_s3 = self.current_state['s3_buckets'][i]
                drift = self._compare_resources(baseline_s3, current_s3, f's3_buckets[{i}]', 'S3 Bucket')
                if drift:
                    drifts.extend(drift)

        # Check Security Groups
        for i, baseline_sg in enumerate(self.baseline_config['security_groups']):
            if i < len(self.current_state['security_groups']):
                current_sg = self.current_state['security_groups'][i]
                drift = self._compare_resources(baseline_sg, current_sg, f'security_groups[{i}]', 'Security Group')
                if drift:
                    drifts.extend(drift)

        # Check RDS instances
        for i, baseline_rds in enumerate(self.baseline_config['rds_instances']):
            if i < len(self.current_state['rds_instances']):
                current_rds = self.current_state['rds_instances'][i]
                drift = self._compare_resources(baseline_rds, current_rds, f'rds_instances[{i}]', 'RDS Instance')
                if drift:
                    drifts.extend(drift)

        self.drift_history = drifts
        return drifts

    def _compare_resources(self, baseline, current, resource_path, resource_type):
        """Compare two resource configurations"""
        drifts = []

        for key, baseline_value in baseline.items():
            if key == 'last_patched' or key == 'last_modified':
                continue

            current_value = current.get(key)

            if baseline_value != current_value:
                severity = self._assess_severity(key, baseline_value, current_value)

                drifts.append({
                    'resource_type': resource_type,
                    'resource_path': resource_path,
                    'resource_id': baseline.get('id') or baseline.get('name'),
                    'field': key,
                    'baseline_value': str(baseline_value),
                    'current_value': str(current_value),
                    'severity': severity,
                    'detected_at': datetime.now(),
                    'compliance_impact': self._check_compliance_impact(key, current_value)
                })

        return drifts

    def _assess_severity(self, field, baseline_value, current_value):
        """Assess the severity of a configuration drift"""
        # Critical security issues
        critical_fields = ['encrypted', 'public_access_blocked', 'publicly_accessible',
                          'mfa_delete', 'deletion_protection']

        if field in critical_fields:
            if baseline_value == True and current_value == False:
                return 'CRITICAL'

        if field == 'encryption' and current_value is None:
            return 'CRITICAL'

        if field == 'ingress_rules' and isinstance(current_value, list):
            for rule in current_value:
                if rule.get('port') == 22 and rule.get('source') == '0.0.0.0/0':
                    return 'CRITICAL'

        # High severity issues
        high_severity_fields = ['multi_az', 'backup_retention', 'security_groups',
                               'iam_role', 'monitoring_interval']

        if field in high_severity_fields:
            return 'HIGH'

        # Medium severity issues
        medium_severity_fields = ['versioning', 'monitoring', 'backup_enabled',
                                 'logging_enabled', 'replication']

        if field in medium_severity_fields:
            return 'MEDIUM'

        # Low severity (informational)
        return 'LOW'

    def _check_compliance_impact(self, field, value):
        """Check if drift impacts compliance standards"""
        compliance_issues = []

        # GDPR compliance
        if field == 'encryption' and value is None:
            compliance_issues.append('GDPR')

        # PCI-DSS compliance
        if field == 'public_access_blocked' and value == False:
            compliance_issues.append('PCI-DSS')

        # SOC2 compliance
        if field in ['monitoring', 'logging_enabled'] and value == False:
            compliance_issues.append('SOC2')

        # HIPAA compliance
        if field == 'backup_enabled' and value == False:
            compliance_issues.append('HIPAA')

        if field == 'multi_az' and value == False:
            compliance_issues.append('SOC2')

        return compliance_issues if compliance_issues else []

    def generate_remediation_scripts(self):
        """Generate automated remediation scripts for detected drifts"""
        if not self.drift_history:
            print("‚ùå No drifts detected. Run detect_configuration_drift() first.")
            return None

        remediation_scripts = []

        for drift in self.drift_history:
            script = self._generate_fix_script(drift)
            if script:
                remediation_scripts.append(script)

        self.remediation_scripts = remediation_scripts
        return remediation_scripts

    def _generate_fix_script(self, drift):
        """Generate remediation script for a specific drift"""
        resource_type = drift['resource_type']
        resource_id = drift['resource_id']
        field = drift['field']
        baseline_value = drift['baseline_value']

        script = {
            'drift_id': hashlib.md5(f"{drift['resource_path']}{field}".encode()).hexdigest()[:8],
            'resource_type': resource_type,
            'resource_id': resource_id,
            'severity': drift['severity'],
            'description': f"Remediate {field} drift on {resource_type} {resource_id}",
            'terraform': '',
            'aws_cli': '',
            'python_boto3': '',
            'rollback_script': '',
            'estimated_downtime': '0 minutes',
            'auto_approve': drift['severity'] != 'CRITICAL'
        }

        # Generate Terraform script
        if resource_type == 'EC2 Instance':
            if field == 'security_groups':
                script['terraform'] = f'''
resource "aws_instance" "{resource_id}" {{
  security_groups = {baseline_value}

  lifecycle {{
    prevent_destroy = true
  }}
}}
'''
                script['aws_cli'] = f'aws ec2 modify-instance-attribute --instance-id {resource_id} --groups {baseline_value}'
                script['python_boto3'] = f'''
import boto3
ec2 = boto3.client('ec2')
ec2.modify_instance_attribute(
    InstanceId='{resource_id}',
    Groups={baseline_value}
)
'''

        elif resource_type == 'S3 Bucket':
            if field == 'encryption':
                script['terraform'] = f'''
resource "aws_s3_bucket_server_side_encryption_configuration" "{resource_id}" {{
  bucket = "{resource_id}"

  rule {{
    apply_server_side_encryption_by_default {{
      sse_algorithm = "AES256"
    }}
  }}
}}
'''
                script['aws_cli'] = f'''aws s3api put-bucket-encryption --bucket {resource_id} --server-side-encryption-configuration '{{"Rules":[{{"ApplyServerSideEncryptionByDefault":{{"SSEAlgorithm":"AES256"}}}}]}}'
'''
                script['python_boto3'] = f'''
import boto3
s3 = boto3.client('s3')
s3.put_bucket_encryption(
    Bucket='{resource_id}',
    ServerSideEncryptionConfiguration={{
        'Rules': [{{'ApplyServerSideEncryptionByDefault': {{'SSEAlgorithm': 'AES256'}}}}]
    }}
)
'''

            elif field == 'public_access_blocked':
                script['terraform'] = f'''
resource "aws_s3_bucket_public_access_block" "{resource_id}" {{
  bucket = "{resource_id}"

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}}
'''
                script['aws_cli'] = f'aws s3api put-public-access-block --bucket {resource_id} --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"'

        elif resource_type == 'RDS Instance':
            if field == 'multi_az':
                script['terraform'] = f'''
resource "aws_db_instance" "{resource_id}" {{
  multi_az = true
  apply_immediately = false
}}
'''
                script['aws_cli'] = f'aws rds modify-db-instance --db-instance-identifier {resource_id} --multi-az --no-apply-immediately'
                script['estimated_downtime'] = '5-10 minutes'

            elif field == 'backup_retention':
                script['terraform'] = f'''
resource "aws_db_instance" "{resource_id}" {{
  backup_retention_period = 30
  apply_immediately = true
}}
'''
                script['aws_cli'] = f'aws rds modify-db-instance --db-instance-identifier {resource_id} --backup-retention-period 30 --apply-immediately'

        # Generate rollback script
        script['rollback_script'] = f"# Rollback: Revert {field} to current value: {drift['current_value']}"

        return script

    def analyze_security_posture(self):
        """Analyze overall security posture based on drifts"""
        if not self.drift_history:
            return None

        severity_counts = {
            'CRITICAL': 0,
            'HIGH': 0,
            'MEDIUM': 0,
            'LOW': 0
        }

        compliance_violations = {}
        resource_types_affected = {}

        for drift in self.drift_history:
            severity_counts[drift['severity']] += 1

            # Count compliance violations
            for compliance in drift['compliance_impact']:
                compliance_violations[compliance] = compliance_violations.get(compliance, 0) + 1

            # Count resource types affected
            rt = drift['resource_type']
            resource_types_affected[rt] = resource_types_affected.get(rt, 0) + 1

        # Calculate security score (0-100)
        total_drifts = len(self.drift_history)
        critical_weight = 10
        high_weight = 5
        medium_weight = 2
        low_weight = 1

        weighted_drifts = (
            severity_counts['CRITICAL'] * critical_weight +
            severity_counts['HIGH'] * high_weight +
            severity_counts['MEDIUM'] * medium_weight +
            severity_counts['LOW'] * low_weight
        )

        max_possible = total_drifts * critical_weight
        security_score = max(0, 100 - (weighted_drifts / max_possible * 100)) if max_possible > 0 else 100

        security_analysis = {
            'total_drifts': total_drifts,
            'severity_breakdown': severity_counts,
            'security_score': round(security_score, 2),
            'compliance_violations': compliance_violations,
            'resource_types_affected': resource_types_affected,
            'risk_level': self._calculate_risk_level(security_score),
            'recommendations': self._generate_security_recommendations(severity_counts, compliance_violations)
        }

        self.security_violations = security_analysis
        return security_analysis

    def _calculate_risk_level(self, score):
        """Calculate overall risk level"""
        if score >= 80:
            return 'LOW'
        elif score >= 60:
            return 'MEDIUM'
        elif score >= 40:
            return 'HIGH'
        else:
            return 'CRITICAL'

    def _generate_security_recommendations(self, severity_counts, compliance_violations):
        """Generate security recommendations"""
        recommendations = []

        if severity_counts['CRITICAL'] > 0:
            recommendations.append({
                'priority': 1,
                'action': 'IMMEDIATE ACTION REQUIRED',
                'description': f"{severity_counts['CRITICAL']} critical security issues detected. Remediate within 4 hours.",
                'impact': 'Data breach risk, compliance violations'
            })

        if severity_counts['HIGH'] > 0:
            recommendations.append({
                'priority': 2,
                'action': 'Address High Severity Issues',
                'description': f"{severity_counts['HIGH']} high severity issues found. Remediate within 24 hours.",
                'impact': 'Reduced availability, potential security gaps'
            })

        if compliance_violations:
            recommendations.append({
                'priority': 1,
                'action': 'Compliance Remediation',
                'description': f"Compliance violations detected: {', '.join(compliance_violations.keys())}",
                'impact': 'Regulatory fines, audit failures'
            })

        if severity_counts['MEDIUM'] > 3:
            recommendations.append({
                'priority': 3,
                'action': 'Improve Configuration Management',
                'description': 'Multiple medium severity issues suggest process gaps',
                'impact': 'Implement drift detection automation and policy enforcement'
            })

        return recommendations

    def visualize_drift_analysis(self):
        """Create comprehensive visualization of drift analysis"""
        if not self.drift_history:
            print("‚ùå No drift data available.")
            return

        fig = plt.figure(figsize=(20, 12))

        # 1. Drift by Severity
        ax1 = plt.subplot(3, 3, 1)
        severity_counts = pd.Series([d['severity'] for d in self.drift_history]).value_counts()
        colors = {'CRITICAL': '#FF0000', 'HIGH': '#FF6B6B', 'MEDIUM': '#FFA500', 'LOW': '#4ECDC4'}
        bars = ax1.bar(severity_counts.index, severity_counts.values,
                      color=[colors.get(s, '#CCCCCC') for s in severity_counts.index],
                      edgecolor='black', linewidth=1.5)
        ax1.set_title('Configuration Drifts by Severity', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Count')
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom', fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='y')

        # 2. Drifts by Resource Type
        ax2 = plt.subplot(3, 3, 2)
        resource_counts = pd.Series([d['resource_type'] for d in self.drift_history]).value_counts()
        ax2.barh(resource_counts.index, resource_counts.values, color='#667eea', edgecolor='black')
        ax2.set_title('Drifts by Resource Type', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Count')
        for i, v in enumerate(resource_counts.values):
            ax2.text(v + 0.1, i, str(v), va='center', fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='x')

        # 3. Security Score Gauge
        ax3 = plt.subplot(3, 3, 3)
        if self.security_violations:
            score = self.security_violations['security_score']
            risk = self.security_violations['risk_level']

            # Create gauge chart
            theta = np.linspace(0, np.pi, 100)
            radius = 1
            x = radius * np.cos(theta)
            y = radius * np.sin(theta)

            # Color segments
            colors_gauge = ['#FF0000', '#FF6B6B', '#FFA500', '#FFD700', '#4ECDC4']
            segments = 5
            for i in range(segments):
                start_angle = i * np.pi / segments
                end_angle = (i + 1) * np.pi / segments
                theta_seg = np.linspace(start_angle, end_angle, 20)
                x_seg = radius * np.cos(theta_seg)
                y_seg = radius * np.sin(theta_seg)
                ax3.fill_between(x_seg, 0, y_seg, color=colors_gauge[i], alpha=0.6)

            # Score needle
            needle_angle = np.pi * (1 - score/100)
            ax3.plot([0, radius * 0.9 * np.cos(needle_angle)],
                    [0, radius * 0.9 * np.sin(needle_angle)],
                    'k-', linewidth=3)
            ax3.plot(0, 0, 'ko', markersize=10)

            ax3.set_xlim(-1.2, 1.2)
            ax3.set_ylim(-0.2, 1.2)
            ax3.set_aspect('equal')
            ax3.axis('off')
            ax3.text(0, -0.1, f'Security Score\n{score:.1f}/100',
                    ha='center', fontsize=14, fontweight='bold')
            ax3.text(0, -0.25, f'Risk: {risk}', ha='center', fontsize=11,
                    color=colors.get(risk, 'black'))
        ax3.set_title('Overall Security Posture', fontsize=14, fontweight='bold')

        # 4. Compliance Violations
        ax4 = plt.subplot(3, 3, 4)
        if self.security_violations and self.security_violations['compliance_violations']:
            comp_violations = self.security_violations['compliance_violations']
            ax4.bar(comp_violations.keys(), comp_violations.values(),
                   color='#f093fb', edgecolor='black')
            ax4.set_title('Compliance Violations', fontsize=14, fontweight='bold')
            ax4.set_ylabel('Count')
            for i, (k, v) in enumerate(comp_violations.items()):
                ax4.text(i, v + 0.1, str(v), ha='center', fontweight='bold')
        else:
            ax4.text(0.5, 0.5, 'No Compliance\nViolations',
                    ha='center', va='center', fontsize=12, color='green', fontweight='bold')
            ax4.set_xlim(0, 1)
            ax4.set_ylim(0, 1)
        ax4.set_title('Compliance Violations', fontsize=14, fontweight='bold')
        ax4.grid(True, alpha=0.3, axis='y')

        # 5. Timeline of Drifts
        ax5 = plt.subplot(3, 3, 5)
        drift_times = [d['detected_at'] for d in self.drift_history]
        severity_colors = [colors.get(d['severity'], '#CCCCCC') for d in self.drift_history]
        ax5.scatter(drift_times, range(len(drift_times)), c=severity_colors, s=100, alpha=0.7, edgecolors='black')
        ax5.set_title('Drift Detection Timeline', fontsize=14, fontweight='bold')
        ax5.set_xlabel('Time')
        ax5.set_ylabel('Drift Event')
        ax5.grid(True, alpha=0.3)
        ax5.tick_params(axis='x', rotation=45)

        # 6. Top Drifted Fields
        ax6 = plt.subplot(3, 3, 6)
        field_counts = pd.Series([d['field'] for d in self.drift_history]).value_counts().head(8)
        ax6.barh(field_counts.index, field_counts.values, color='#45B7D1', edgecolor='black')
        ax6.set_title('Most Frequently Drifted Fields', fontsize=14, fontweight='bold')
        ax6.set_xlabel('Count')
        for i, v in enumerate(field_counts.values):
            ax6.text(v + 0.05, i, str(v), va='center', fontweight='bold')
        ax6.grid(True, alpha=0.3, axis='x')

        # 7. Remediation Status
        ax7 = plt.subplot(3, 3, 7)
        if self.remediation_scripts:
            auto_approve = sum(1 for s in self.remediation_scripts if s['auto_approve'])
            manual_approve = len(self.remediation_scripts) - auto_approve

            labels = ['Auto-Remediate', 'Manual Review']
            sizes = [auto_approve, manual_approve]
            colors_pie = ['#4ECDC4', '#FFA500']
            explode = (0.05, 0.05)

            ax7.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors_pie,
                   explode=explode, shadow=True, startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})
        ax7.set_title('Remediation Strategy', fontsize=14, fontweight='bold')

        # 8. Severity Distribution (Donut)
        ax8 = plt.subplot(3, 3, 8)
        severity_data = pd.Series([d['severity'] for d in self.drift_history]).value_counts()
        colors_donut = [colors.get(s, '#CCCCCC') for s in severity_data.index]
        wedges, texts, autotexts = ax8.pie(severity_data.values, labels=severity_data.index,
                                            autopct='%1.1f%%', colors=colors_donut,
                                            startangle=90, pctdistance=0.85,
                                            textprops={'fontsize': 10, 'weight': 'bold'})

        # Draw circle for donut
        centre_circle = plt.Circle((0, 0), 0.70, fc='white')
        ax8.add_artist(centre_circle)
        ax8.text(0, 0, f'{len(self.drift_history)}\nDrifts', ha='center', va='center',
                fontsize=16, fontweight='bold')
        ax8.set_title('Severity Distribution', fontsize=14, fontweight='bold')

        # 9. Affected Resources Summary
        ax9 = plt.subplot(3, 3, 9)
        affected_resources = {}
        for drift in self.drift_history:
            res_id = drift['resource_id']
            affected_resources[res_id] = affected_resources.get(res_id, 0) + 1

        if affected_resources:
            top_affected = dict(sorted(affected_resources.items(), key=lambda x: x[1], reverse=True)[:8])
            bars = ax9.barh(list(top_affected.keys()), list(top_affected.values()),
                           color='#FF6B6B', edgecolor='black')
            ax9.set_title('Most Affected Resources', fontsize=14, fontweight='bold')
            ax9.set_xlabel('Number of Drifts')
            for i, v in enumerate(top_affected.values()):
                ax9.text(v + 0.05, i, str(v), va='center', fontweight='bold')
        ax9.grid(True, alpha=0.3, axis='x')

        plt.tight_layout()
        plt.savefig('iac_drift_analysis.png', dpi=300, bbox_inches='tight')
        print("\n‚úì Visualization saved as 'iac_drift_analysis.png'")
        plt.show()

    def generate_report(self):
        """Generate comprehensive drift detection report"""
        print("\n" + "="*80)
        print("üîç INFRASTRUCTURE AS CODE - DRIFT DETECTION REPORT")
        print("="*80)

        # Summary
        print("\nüìä DRIFT DETECTION SUMMARY")
        print("-" * 80)
        print(f"Total Configuration Drifts:     {len(self.drift_history)}")

        if self.drift_history:
            severity_counts = {}
            for drift in self.drift_history:
                sev = drift['severity']
                severity_counts[sev] = severity_counts.get(sev, 0) + 1

            print(f"  ‚Ä¢ Critical:                   {severity_counts.get('CRITICAL', 0)}")
            print(f"  ‚Ä¢ High:                       {severity_counts.get('HIGH', 0)}")
            print(f"  ‚Ä¢ Medium:                     {severity_counts.get('MEDIUM', 0)}")
            print(f"  ‚Ä¢ Low:                        {severity_counts.get('LOW', 0)}")

        # Security Analysis
        if self.security_violations:
            print("\nüîí SECURITY POSTURE ANALYSIS")
            print("-" * 80)
            print(f"Security Score:                 {self.security_violations['security_score']:.1f}/100")
            print(f"Overall Risk Level:             {self.security_violations['risk_level']}")

            if self.security_violations['compliance_violations']:
                print(f"\nCompliance Violations:")
                for comp, count in self.security_violations['compliance_violations'].items():
                    print(f"  ‚Ä¢ {comp}: {count} violation(s)")

        # Critical Issues
        critical_drifts = [d for d in self.drift_history if d['severity'] == 'CRITICAL']
        if critical_drifts:
            print("\nüö® CRITICAL SECURITY ISSUES (IMMEDIATE ACTION REQUIRED)")
            print("-" * 80)
            for i, drift in enumerate(critical_drifts[:5], 1):
                print(f"\n{i}. {drift['resource_type']}: {drift['resource_id']}")
                print(f"   Field:              {drift['field']}")
                print(f"   Baseline Value:     {drift['baseline_value']}")
                print(f"   Current Value:      {drift['current_value']}")
                if drift['compliance_impact']:
                    print(f"   Compliance Impact:  {', '.join(drift['compliance_impact'])}")
                print(f"   Detected:           {drift['detected_at'].strftime('%Y-%m-%d %H:%M:%S')}")

        # Remediation Summary
        if self.remediation_scripts:
            print("\nüîß REMEDIATION PLAN")
            print("-" * 80)
            auto_scripts = sum(1 for s in self.remediation_scripts if s['auto_approve'])
            manual_scripts = len(self.remediation_scripts) - auto_scripts

            print(f"Total Remediation Scripts:      {len(self.remediation_scripts)}")
            print(f"  ‚Ä¢ Auto-remediate (Low Risk):  {auto_scripts}")
            print(f"  ‚Ä¢ Manual Review Required:     {manual_scripts}")

            # Show sample remediation
            if self.remediation_scripts:
                print(f"\nüìù SAMPLE REMEDIATION SCRIPT (First Critical Issue)")
                print("-" * 80)
                sample = next((s for s in self.remediation_scripts if s['severity'] == 'CRITICAL'),
                             self.remediation_scripts[0])

                print(f"Resource:     {sample['resource_type']} - {sample['resource_id']}")
                print(f"Severity:     {sample['severity']}")
                print(f"Description:  {sample['description']}")
                print(f"Downtime:     {sample['estimated_downtime']}")
                print(f"\nTerraform Code:")
                print(sample['terraform'])
                print(f"\nAWS CLI Command:")
                print(sample['aws_cli'])

        # Recommendations
        if self.security_violations and self.security_violations['recommendations']:
            print("\nüí° SECURITY RECOMMENDATIONS")
            print("-" * 80)
            for rec in self.security_violations['recommendations']:
                print(f"\nPriority {rec['priority']}: {rec['action']}")
                print(f"  {rec['description']}")
                print(f"  Impact: {rec['impact']}")

        # Resource Impact
        print("\nüì¶ AFFECTED RESOURCES")
        print("-" * 80)
        if self.security_violations and self.security_violations['resource_types_affected']:
            for resource_type, count in self.security_violations['resource_types_affected'].items():
                print(f"  ‚Ä¢ {resource_type}: {count} drift(s)")

        print(f"\n{'='*80}\n")

def main():
    print("üîç Infrastructure as Code - Drift Detection & Auto-Remediation")
    print("=" * 80)

    detector = IaCDriftDetector()

    # Step 1: Generate baseline infrastructure
    print("\nüìã Step 1: Generating baseline infrastructure configuration...")
    baseline = detector.generate_baseline_infrastructure()
    total_resources = (len(baseline['ec2_instances']) + len(baseline['s3_buckets']) +
                      len(baseline['security_groups']) + len(baseline['rds_instances']))
    print(f"‚úì Baseline created with {total_resources} resources")

    # Step 2: Simulate drift
    print("\nüåä Step 2: Simulating infrastructure drift (manual changes, misconfigurations)...")
    current_state, drift_scenarios = detector.simulate_infrastructure_drift()
    print(f"‚úì Simulated {len(drift_scenarios)} drift scenario(s)")

    # Step 3: Detect drift
    print("\nüîç Step 3: Scanning for configuration drift...")
    drifts = detector.detect_configuration_drift()
    print(f"‚úì Detected {len(drifts)} configuration drift(s)")

    # Step 4: Analyze security posture
    print("\nüîí Step 4: Analyzing security posture and compliance impact...")
    security_analysis = detector.analyze_security_posture()
    if security_analysis:
        print(f"‚úì Security Score: {security_analysis['security_score']:.1f}/100")
        print(f"‚úì Risk Level: {security_analysis['risk_level']}")

    # Step 5: Generate remediation scripts
    print("\nüîß Step 5: Generating automated remediation scripts...")
    remediation = detector.generate_remediation_scripts()
    if remediation:
        print(f"‚úì Generated {len(remediation)} remediation script(s)")

    # Step 6: Generate report
    print("\nüìä Step 6: Generating comprehensive report...")
    detector.generate_report()

    # Step 7: Visualize
    print("\nüìä Step 7: Creating drift analysis visualizations...")
    detector.visualize_drift_analysis()

    print("\n‚úÖ Drift detection and remediation analysis complete!")
    print("\nüìÅ Generated files:")
    print("  - iac_drift_analysis.png (9-panel dashboard)")
    print("\nüí° Next Steps:")
    print("  1. Review critical security issues immediately")
    print("  2. Execute auto-approved remediation scripts")
    print("  3. Schedule manual review for high-risk changes")
    print("  4. Implement drift detection in CI/CD pipeline")
    print("  5. Set up alerts for future configuration changes")

if __name__ == "__main__":
    main()